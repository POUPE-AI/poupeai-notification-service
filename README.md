# Notification Service

Servi√ßo de notifica√ß√µes usando FastAPI.

## Estrutura do Projeto

```
poupeai-notification-service
‚îú‚îÄ‚îÄ requirements/
‚îÇ¬† ¬†‚îî‚îÄ‚îÄ base.txt¬†
‚îú‚îÄ‚îÄ src/
‚îÇ¬† ¬†‚îú‚îÄ‚îÄ notification_service/
‚îÇ¬† ¬†‚îÇ¬† ¬†‚îú‚îÄ‚îÄ __init__.py
‚îÇ¬† ¬†‚îÇ¬† ¬†‚îú‚îÄ‚îÄ templates/         # Templates de e-mail (HTML)
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ invoice_due_soon.html
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ¬† ¬†‚îÇ¬† ¬†‚îú‚îÄ‚îÄ consumer.py¬† ¬†     # L√≥gica do consumidor RabbitMQ
‚îÇ¬† ¬†‚îÇ¬† ¬†‚îú‚îÄ‚îÄ exceptions.py¬†     # Exce√ß√µes personalizadas
‚îÇ¬† ¬†‚îÇ¬† ¬†‚îú‚îÄ‚îÄ router.py¬† ¬† ¬†     # Endpoints HTTP (sem uso no momento)
‚îÇ¬† ¬†‚îÇ¬† ¬†‚îú‚îÄ‚îÄ schemas.py¬† ¬† ¬†    # Schemas de valida√ß√£o (Pydantic)
‚îÇ¬† ¬†‚îÇ¬† ¬†‚îî‚îÄ‚îÄ service.py¬† ¬† ¬†    # L√≥gica de neg√≥cio e manipula√ß√£o de eventos
‚îÇ¬† ¬†‚îÇ
‚îÇ¬† ¬†‚îú‚îÄ‚îÄ __init__.py
‚îÇ¬† ¬†‚îú‚îÄ‚îÄ config.py¬† ¬† ¬† ¬† ¬†     # Configura√ß√µes globais (via Pydantic)
‚îÇ¬† ¬†‚îú‚îÄ‚îÄ redis_client.py ¬† ¬†    # Configura√ß√£o da conex√£o com Redis
‚îÇ¬† ¬†‚îú‚îÄ‚îÄ logging_config.py ¬† ¬†  # Configura√ß√£o dos logs
‚îÇ¬† ¬†‚îî‚îÄ‚îÄ main.py¬† ¬† ¬† ¬† ¬† ¬† ¬†   # Ponto de entrada da aplica√ß√£o FastAPI
‚îÇ
‚îú‚îÄ‚îÄ .env.example
‚îú‚îÄ‚îÄ docker-compose.yml
‚îú‚îÄ‚îÄ .gitignore
‚îî‚îÄ‚îÄ¬† README.md
```

## Arquitetura e Padr√µes de Projeto

- **Processamento Ass√≠ncrono com Filas:** O RabbitMQ √© usado para receber e processar eventos de notifica√ß√£o de forma ass√≠ncrona, garantindo que o sistema de origem n√£o precise esperar pela conclus√£o do envio.
- **Idempot√™ncia:** Cada evento de notifica√ß√£o cont√©m um `message_id` √∫nico. O servi√ßo utiliza o Redis para rastrear os IDs das mensagens j√° processadas com sucesso, prevenindo envios duplicados em caso de reentregas pela fila.
- **Estrat√©gia de Retry e Dead-Letter Queue (DLQ):** A arquitetura de filas implementa um padr√£o de retentativas com delay para falhas transientes (ex: falha de conex√£o com o servidor de e-mail) e move mensagens com falhas permanentes ou que excederam o limite de tentativas para uma DLQ.

## Instala√ß√£o e Execu√ß√£o

Siga os passos abaixo para configurar e executar o projeto localmente.

### 1. Configurar Vari√°veis de Ambiente

As configura√ß√µes da aplica√ß√£o, como conex√µes com bancos de dados e servi√ßos externos (RabbitMQ, Redis, etc.), s√£o carregadas a partir de vari√°veis de ambiente.

Copie o arquivo de template `.env.example` para criar seu pr√≥prio arquivo de configura√ß√£o local `.env`.

```bash
cp .env.example .env
```

Ap√≥s copiar, **abra o arquivo `.env`** e preencha os valores para cada vari√°vel com as suas credenciais e configura√ß√µes de ambiente.

### 2. Instalar depend√™ncias

```bash
pip install -r requirements\base.txt
```

### 3. Executar o servi√ßo

```bash
cd src
python main.py
```

O servi√ßo ser√° iniciado usando as configura√ß√µes definidas em `config.py`:

- Host: localhost
- Porta: 8001

Tamb√©m √© poss√≠vel executar usando o uvicorn diretamente especificando a porta

```bash
uvicorn main:app --reload --port 8001
```

## Ambiente de Desenvolvimento com Docker Compose

O m√©todo recomendado para executar o projeto localmente √© usando Docker Compose. Ele ir√° configurar a aplica√ß√£o, o RabbitMQ e o Redis automaticamente.

> **Nota:** Este `docker-compose.yml` foi projetado para o desenvolvimento isolado deste servi√ßo. Para executar a stack completa da aplica√ß√£o, com todos os microsservi√ßos integrados, utilize o arquivo `docker-compose.yml` principal localizado no reposit√≥rio `.gitbub` da organiza√ß√£o.

### 1. Pr√©-requisitos

- Docker e Docker Compose instalados.
- Crie um arquivo `.env` a partir do template `.env.example` e preencha as vari√°veis, se necess√°rio.

```bash
cp .env.example .env
```

### 2 Iniciar o Ambiente

Na raiz do projeto, execute o seguinte comando para construir as imagens e iniciar os cont√™ineres:

```bash
docker-compose up --build -d
```

### 3 Verificar os Servi√ßos

Ap√≥s a execu√ß√£o, os seguintes servi√ßos estar√£o dispon√≠veis:

- **API do Servi√ßo de Notifica√ß√£o**: `http://localhost:8001`
  - **Swagger UI**: `http://localhost:8001/api/v1/docs`
- **Interface de Gerenciamento do RabbitMQ**: `http://localhost:15672`
  - Use as credenciais `RABBITMQ_USER` e `RABBITMQ_PASSWORD` definidas no seu arquivo `.env`.

Para visualizar os logs da aplica√ß√£o em tempo real, use:

```bash
docker-compose logs -f app
```

### 4 Parar o Ambiente

Para parar todos os cont√™ineres, execute:

```bash
docker-compose down
```

Se desejar remover tamb√©m os volumes de dados (todas as mensagens e dados do Redis ser√£o perdidos), execute:

```bash
docker-compose down -v
```

### Health Check

- **GET** `/api/v1/health` - Verifica o status da aplica√ß√£o e a conectividade com o Redis.

## Logging

O servi√ßo utiliza a biblioteca `structlog` para gerar logs estruturados no formato JSON. Essa abordagem padroniza a sa√≠da de logs, facilitando a coleta, busca e an√°lise em ambientes centralizados. Todos os logs incluem campos importantes como `correlation_id`, `event_type` e `timestamp`, permitindo uma rastreabilidade detalhada das opera√ß√µes.

Os logs gerados s√£o enviados para a sa√≠da padr√£o (`stdout`) e s√£o coletados pela nossa stack de logging central (**Promtail/Loki/Grafana**), onde podem ser consultados e correlacionados com eventos de outros servi√ßos.

## Estrat√©gia de Filas (RabbitMQ)

O servi√ßo utiliza o RabbitMQ para processamento ass√≠ncrono de notifica√ß√µes, implementando uma estrat√©gia resiliente com **retentativas autom√°ticas** para falhas tempor√°rias e uma **Dead-Letter Queue (DLQ)** para erros irrecuper√°veis.

### Topologia

A arquitetura √© composta por um conjunto de filas e exchanges que trabalham juntas para garantir que nenhuma mensagem seja perdida. Os nomes exatos das entidades (ex: `notification_events`, `notification_exchange`) s√£o carregados a partir de vari√°veis de ambiente para flexibilidade.

1.  **Exchange Principal (`notification_exchange`)**

    - **Tipo:** `Direct`
    - **Responsabilidade:** Ponto de entrada para todas as novas mensagens de notifica√ß√£o.

2.  **Fila Principal (`notification_events`)**

    - **Tipo:** `Durable`
    - **Responsabilidade:** Armazena novas mensagens aguardando a **primeira tentativa** de processamento.

3.  **Exchange de Retry (`notification_exchange.retry`)**

    - **Tipo:** `Direct`
    - **Responsabilidade:** Receber mensagens que falharam no processamento devido a um erro tempor√°rio.

4.  **Fila de Retry (`notification_events.retry`)**

    - **Tipo:** `Durable`
    - **Responsabilidade:** Reter temporariamente as mensagens que falharam. Possui um **TTL (Time-To-Live)** que, ao expirar, envia a mensagem de volta √† Exchange Principal para uma nova tentativa.

5.  **Dead-Letter Exchange Final (DLX) (`notification_exchange.dlq`)**

    - **Tipo:** `Direct`
    - **Responsabilidade:** Ponto de entrada para mensagens que **n√£o podem ou n√£o devem mais ser processadas**.

6.  **Fila de Dead-Letter Final (DLQ) (`notification_events.dlq`)**

    - **Tipo:** `Durable`
    - **Responsabilidade:** Armazenar permanentemente mensagens com **erros irrecuper√°veis** (ex: falha de valida√ß√£o) ou que **excederam o limite de retentativas**.

### Contrato da Mensagem e Payloads de Exemplo

Para ser processada corretamente, toda mensagem enviada ao `notification_exchange` deve seguir um contrato espec√≠fico, dividido entre as **Propriedades** da mensagem e o **Corpo** (Payload).

#### Propriedades da Mensagem

As seguintes propriedades devem ser configuradas ao publicar a mensagem:

| Propriedade      | Valor Exemplo        | Obrigat√≥rio | Descri√ß√£o                                                   |
| :--------------- | :------------------- | :---------- | :---------------------------------------------------------- |
| `routing_key`    | `notification.event` | Sim         | Chave de roteamento para ligar a exchange √† fila principal. |
| `correlation_id` | `"trace-abc-123"`    | Sim         | Identificador para rastreabilidade e logs ponta a ponta.    |
| `content_type`   | `application/json`   | Sim         | Indica que o corpo da mensagem √© um JSON.                   |

**√â fundamental que todo produtor de mensagens garanta a inclus√£o e o repasse do `correlation_id`. Este identificador √© a chave para a rastreabilidade ponta a ponta da requisi√ß√£o atrav√©s dos diferentes microsservi√ßos e para a depura√ß√£o de problemas utilizando a stack de logging centralizada.**

#### Corpo da Mensagem (Payload)

O corpo da mensagem deve ser um objeto JSON que segue a estrutura abaixo. O campo `message_id` √© usado para controle de idempot√™ncia.

<details open>
<summary><strong><code>INVOICE_DUE_SOON</code> - Fatura Pr√≥xima do Vencimento</strong></summary>

```json
{
  "message_id": "a1b2c3d4-e5f6-7890-1234-567890abcdef",
  "timestamp": "2025-07-20T10:00:00Z",
  "trigger_type": "system_scheduled",
  "event_type": "INVOICE_DUE_SOON",
  "recipient": {
    "user_id": "user-987",
    "email": "maria.santos@email.com",
    "name": "Maria Santos"
  },
  "payload": {
    "credit_card": "Cart√£o BB",
    "month": 7,
    "year": 2025,
    "due_date": "2025-07-25",
    "amount": 150.5,
    "invoice_deep_link": "poupeai://app/invoices/inv-2025-07-1234"
  }
}
```

</details>

<details>
<summary><strong><code>INVOICE_OVERDUE</code> - Fatura Vencida</strong></summary>

```json
{
  "message_id": "b2c3d4e5-f6a7-8901-2345-67890abcdef1",
  "timestamp": "2025-07-26T09:00:00Z",
  "trigger_type": "system_scheduled",
  "event_type": "INVOICE_OVERDUE",
  "recipient": {
    "user_id": "user-987",
    "email": "maria.santos@email.com",
    "name": "Maria Santos"
  },
  "payload": {
    "credit_card": "Cart√£o BB",
    "month": 7,
    "year": 2025,
    "due_date": "2025-07-25",
    "amount": 150.5,
    "days_overdue": 1,
    "invoice_deep_link": "poupeai://app/invoices/inv-2025-07-1234"
  }
}
```

</details>

<details>
<summary><strong><code>PROFILE_DELETION_SCHEDULED</code> - Exclus√£o de Perfil Agendada</strong></summary>

```json
{
  "message_id": "c3d4e5f6-a7b8-9012-3456-7890abcdef12",
  "timestamp": "2025-08-01T18:00:00Z",
  "trigger_type": "user_action",
  "event_type": "PROFILE_DELETION_SCHEDULED",
  "recipient": {
    "user_id": "user-456",
    "email": "carlos.pereira@email.com",
    "name": "Carlos Pereira"
  },
  "payload": {
    "deletion_scheduled_at": "2025-09-01T18:00:00Z",
    "reactivate_account_deep_link": "poupeai://app/account/reactivate"
  }
}
```

</details>

### Fluxo da Mensagem

O caminho que uma mensagem percorre depende do resultado de seu processamento.

1.  **Publica√ß√£o:** Um produtor envia uma mensagem para a `notification_exchange`.

2.  **Primeira Tentativa:** A exchange roteia a mensagem para a `notification_events`, e o consumidor a pega para processar.

    - ‚úÖ **Caminho Feliz:** A l√≥gica de neg√≥cio √© executada com sucesso. A mensagem √© confirmada (`ACK`) e removida permanentemente do sistema. A chave de idempot√™ncia (`message_id`) √© gravada no Redis.

    - ‚ùå **Caminho de Erro Irrecuper√°vel:** A mensagem falha na valida√ß√£o inicial (ex: JSON inv√°lido, schema incorreto). O consumidor publica a mensagem diretamente na `notification_exchange.dlq` e d√° `ACK` na mensagem original. O ciclo termina.

    - üîÑ **Caminho de Erro Tempor√°rio:** A l√≥gica de neg√≥cio falha (ex: servi√ßo externo indispon√≠vel). O consumidor publica a mensagem na `notification_exchange.retry` e d√° `ACK` na mensagem original.

3.  **Ciclo de Retentativa:**

    - A mensagem entra na `notification_events.retry` e aguarda o TTL expirar.
    - Ao expirar, ela √© roteada de volta para a `notification_exchange` e entra novamente na `notification_events` para uma nova tentativa.
    - O consumidor pega a mensagem e verifica o n√∫mero de tentativas anteriores no header `x-death`.
    - Se o limite de tentativas n√£o foi atingido, o passo 2 se repete.
    - Se o limite de tentativas **foi atingido**, o consumidor considera a falha como permanente, publica a mensagem na `notification_exchange.dlq` e d√° `ACK` na mensagem original, encerrando o ciclo.

## Documenta√ß√£o

- Swagger: http://localhost:8001/api/v1/docs

## Testes

O projeto utiliza `pytest` para testes automatizados. A estrat√©gia de teste inclui testes unit√°rios (j√° implementados) e testes de integra√ß√£o (planejados, mas ainda n√£o implementados).

### Pr√©-requisitos para Testes

1.  **Ambiente Virtual Ativo:** Certifique-se de que seu ambiente virtual (`venv`) esteja ativado.
2.  **Depend√™ncias de Teste Instaladas:** Instale as bibliotecas necess√°rias para rodar os testes unit√°rios e gerar cobertura:

        pip install -r requirements/base.txt

3.  **Para Testes de Integra√ß√£o (Quando Implementados):** O ambiente Docker Compose dever√° estar rodando em segundo plano (`docker compose up -d`).

### Executando os Testes Unit√°rios

Todos os comandos de teste devem ser executados a partir da **raiz do projeto**.

Este comando executa rapidamente todos os testes unit√°rios implementados, que validam a l√≥gica interna do servi√ßo sem depender de servi√ßos externos (RabbitMQ, Redis).

    pytest tests/unit/

Voc√™ tamb√©m pode rodar com mais detalhes (mostrando o nome de cada teste) usando a flag `-v`:

    pytest -v tests/unit/

### Testes de Integra√ß√£o (Planejados)

Os testes de integra√ß√£o foram planejados (ver casos IT-001 a IT-003 no Plano de Teste) para validar a intera√ß√£o do servi√ßo com os cont√™ineres Docker (RabbitMQ, Redis). **Estes testes ainda n√£o foram implementados.**

Quando forem implementados, o comando para execut√°-los (assumindo que usem o marcador `integration`) ser√°:

    # Comando FUTURO - Requer Docker rodando e testes implementados
    docker compose exec app pytest -m integration -v tests/integration/

### Gerando o Relat√≥rio de Cobertura (Coverage)

Para verificar qual porcentagem do c√≥digo da aplica√ß√£o (`src/`) √© coberta pelos testes unit√°rios e gerar o relat√≥rio HTML:

**M√©todo Recomendado (Com Link Clic√°vel no Terminal):**

    # 1. Executa os testes unit√°rios medindo a cobertura apenas do c√≥digo 'src/'
    coverage run --source=src -m pytest tests/unit/

    # 2. Gera o relat√≥rio HTML e mostra o link no terminal
    coverage html

Ap√≥s executar `coverage html`, procure a linha `Wrote HTML report to htmlcov/index.html` no terminal. Abra este arquivo no seu navegador (pode ser necess√°rio usar Ctrl+Click no link gerado pelo comando `echo "file://$(pwd)/htmlcov/index.html"` se o link direto n√£o funcionar) para ver o relat√≥rio detalhado. A cobertura atual com testes unit√°rios √© de aproximadamente 67% do c√≥digo em `src/`.

**Alternativa (Com Resumo no Terminal e Relat√≥rio HTML):**

    # Executa os testes unit√°rios e gera o relat√≥rio HTML de uma vez
    pytest --cov=src --cov-report=html tests/unit/

Este comando tamb√©m cria a pasta `htmlcov/` com o relat√≥rio, e o resumo de cobertura j√° aparece no terminal.

### Limpando Arquivos de Cobertura

Para remover os arquivos gerados pelo coverage:

    coverage erase
    rm -rf htmlcov/

**(Nota:** A pasta `htmlcov/` e o arquivo `.coverage` est√£o inclu√≠dos no `.gitignore` para n√£o serem enviados ao reposit√≥rio).\*
